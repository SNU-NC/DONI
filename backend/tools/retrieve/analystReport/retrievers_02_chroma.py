"""
ë¦¬í¬íŠ¸ ê²€ìƒ‰ê¸°(Retriever) êµ¬í˜„ ëª¨ë“ˆ
"""

from typing import List, Optional, Dict, Any, Sequence, Callable, Union
from uuid import UUID
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from langchain_core.callbacks import BaseCallbackHandler
from langchain_community.query_constructors.chroma import ChromaTranslator
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models import BaseLanguageModel
from langchain.retrievers import ContextualCompressionRetriever
from datetime import datetime
import logging


class ReportQueryRewriter:
    """ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ì— íŠ¹í™”ëœ ì¿¼ë¦¬ ì¬ì‘ì„±ê¸°"""
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.prompt = PromptTemplate(
            template="""ë‹¹ì‹ ì€ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ê²€ìƒ‰ì„ ìœ„í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ ê²€ìƒ‰ì–´ë¥¼ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ì „ë¬¸ ìš©ì–´ì™€ í‘œí˜„ìœ¼ë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”.

        ì˜ˆì‹œ:
        - ì…ë ¥: "ì‹¤ì ì´ ì–´ë–¤ê°€ìš”"
          ì¶œë ¥: "ë§¤ì¶œì•¡ ì˜ì—…ì´ìµ ìˆœì´ìµ ì‹¤ì  ì¶”ì´ ì „ë§"
        - ì…ë ¥: "íˆ¬ìì˜ê²¬ ì•Œë ¤ì¤˜"
          ì¶œë ¥: "íˆ¬ìì˜ê²¬ ëª©í‘œì£¼ê°€ íˆ¬ìí¬ì¸íŠ¸ ë°¸ë¥˜ì—ì´ì…˜"
        - ì…ë ¥: "ë§¤ì¶œ"
          ì¶œë ¥: "ë§¤ì¶œì•¡ ì˜ì—…ìˆ˜ìµ ì‚¬ì—…ë¶€ë¬¸ë³„ ë§¤ì¶œ êµ¬ì„±"
        
        ì›ë³¸ ê²€ìƒ‰ì–´: {query}
        
        ì• ë„ë¦¬ìŠ¤íŠ¸ ë³´ê³ ì„œ ìš©ì–´ë¡œ ì¬êµ¬ì„±í•œ ê²€ìƒ‰ì–´:""",
            input_variables=["query"]
        )
        
    def rewrite_query(self, query: str) -> str:
        # ë”°ì˜´í‘œ ì œê±° ë° context ë¶„ë¦¬
        if ", context=" in query:
            query = query.split(", context=")[0]  # context ë¶€ë¶„ ì œê±°
        query = query.strip('"')
        
        chain = self.prompt | self.llm | StrOutputParser()
        return chain.invoke({"query": query})

class ReportLLMChainExtractor(LLMChainExtractor):
    """ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ì— íŠ¹í™”ëœ ë¬¸ì„œ ì••ì¶•ê¸°"""
    
    @classmethod
    def from_llm(
        cls,
        llm: BaseLanguageModel,
        prompt: Optional[PromptTemplate] = None,
        get_input: Optional[Callable[[str, Document], str]] = None,
    ) -> "ReportLLMChainExtractor":
        """LLMìœ¼ë¡œë¶€í„° ì´ˆê¸°í™”"""
        
        def _get_input(query: str, doc: Document) -> dict:
            """ì¿¼ë¦¬ì™€ ë¬¸ì„œ ë‚´ìš©ì„ LLMChain ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
            return {
                "query": query,
                "text": doc.page_content
            }
            
        _prompt = PromptTemplate(
            template="""ë‹¤ìŒ ë¦¬í¬íŠ¸ ë‚´ìš©ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.
            ë¦¬í¬íŠ¸ì˜ element_typeì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì´ ì²˜ë¦¬í•´ì£¼ì„¸ìš”:
            
            1. textì¸ ê²½ìš°: 
               - ì‹¤ì , íˆ¬ìì˜ê²¬, ëª©í‘œì£¼ê°€ ë“± ì •ëŸ‰ì  ë°ì´í„° ìœ„ì£¼ë¡œ ì¶”ì¶œ
               - ë¶„ì„ì˜ í•µì‹¬ ê·¼ê±°ë‚˜ ì¤‘ìš” ì „ë§ í¬í•¨
            
            2. imageì¸ ê²½ìš°:
               - ì°¨íŠ¸/ê·¸ë˜í”„ê°€ ë³´ì—¬ì£¼ëŠ” ì¶”ì„¸ë‚˜ íŒ¨í„´ ì„¤ëª…
               - ì£¼ìš” ìˆ˜ì¹˜ë“¤ì˜ ë³€í™” ë‚´ìš© ëª…ì‹œ
               
            ì¤‘ìš” ì§€ì¹¨:
            1. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë¬´ê´€í•œ ë‚´ìš©ì€ ì œì™¸
            2. ì‹œê¸°ë³„ ë°ì´í„°ëŠ” ì—°ë„/ë¶„ê¸° ëª…ì‹œ
            3. ê´€ë ¨ì„±ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¬¸ìì—´("") ë°˜í™˜
            4. ìš”ì•½ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ ì¤‘ì‹¬ìœ¼ë¡œ
            
            ì‚¬ìš©ì ì§ˆë¬¸: {query}
            
            ë¦¬í¬íŠ¸ ë‚´ìš©:
            {text}
            
            ê´€ë ¨ ì •ë³´ ì¶”ì¶œ:""",
            input_variables=["query", "text"]  # ë³€ìˆ˜ëª… ë³€ê²½
        )
        
        _get_input = _get_input if get_input is None else get_input
        
        if _prompt.output_parser is not None:
            parser = _prompt.output_parser
        else:
            parser = StrOutputParser()
            
        llm_chain = _prompt | llm | parser
        return cls(llm_chain=llm_chain, get_input=_get_input)

class SearchDebugHandler(BaseCallbackHandler):
    """ê²€ìƒ‰ ê³¼ì •ì˜ ë””ë²„ê¹…ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    
    def on_chain_end(self, outputs: Any, *, run_id: UUID, parent_run_id: UUID | None = None, **kwargs: Any) -> Any:
        if hasattr(outputs, "filter") or hasattr(outputs, "query"):
            print("\n" + "="*50)
            print("ğŸ” êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ìƒì„± ê²°ê³¼")
            print("="*50)
            filter_condition = getattr(outputs, "filter", None)
            query = getattr(outputs, "query", None)
            print(f"í•„í„° ì¡°ê±´: {filter_condition}")
            print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
            print("="*50 + "\n")

    def on_retriever_start(self, serialized: Dict[str, Any], query: str, **kwargs: Any) -> Any:
        print("\n" + "="*50)
        print("ğŸš€ ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘")
        print("="*50)
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        print("="*50 + "\n")

    def on_retriever_end(self, documents: Sequence[Document], **kwargs: Any) -> Any:
        print("\n" + "="*50)
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ - {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
        print("="*50)
        for i, doc in enumerate(documents, 1):
            print(f"\nğŸ“„ ë¬¸ì„œ {i}:")
            print(f"ë‚´ìš©: {doc.page_content}")
            print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
        print("="*50 + "\n")

    def on_retriever_error(self, error: BaseException, **kwargs: Any) -> Any:
        print("\n" + "="*50)
        print("âŒ ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ")
        print("="*50)
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(error)}")
        print("="*50 + "\n")

class CompressionDebugHandler(BaseCallbackHandler):
    """ì••ì¶• ê³¼ì •ì˜ ë””ë²„ê¹…ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""

    def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any) -> Any:
        print("\n" + "="*50)
        print("ğŸ” ë¬¸ì„œ ì••ì¶• ì‹œì‘")
        print("="*50)
        print(f"ì…ë ¥ í”„ë¡¬í”„íŠ¸: {prompts[0][:200]}...")
        print("="*50 + "\n")

    def on_llm_end(self, response: Any, **kwargs: Any) -> Any:
        print("\n" + "="*50)
        print("âœ… ë¬¸ì„œ ì••ì¶• ì™„ë£Œ")
        print("="*50)
        if hasattr(response, 'generations'):
            text = response.generations[0][0].text if response.generations else "ì‘ë‹µ ì—†ìŒ"
            print(f"ì••ì¶• ê²°ê³¼: {text[:200]}...")
        else:
            print("ì‘ë‹µ í˜•ì‹ì´ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤.")
        print("="*50 + "\n")

    def on_llm_error(self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any) -> Any:
        print("\n" + "="*50)
        print("âŒ ë¬¸ì„œ ì••ì¶• ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        print("="*50)
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(error)}")
        print("="*50 + "\n")

class RetrievalManager:
    """ê²€ìƒ‰ê¸° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, vectorstore, llm: Optional[ChatOpenAI] = None):
        self.logger = logging.getLogger(self.__class__.__name__)
        self.vectorstore = vectorstore
        self.llm = llm or ChatOpenAI(model="gpt-4o", temperature=0)
        self.query_rewriter = ReportQueryRewriter(self.llm)

        # ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ˆê¸°í™”
        self.analysis_prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="""ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ 
            í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ ë¶„ì„í•´ì£¼ì„¸ìš”:
            
            1. ì‹œê¸°ë³„ ë°ì´í„° ë³€í™”ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª… (ë¶„ê¸°ë³„/ì—°ë„ë³„)
            2. í•µì‹¬ ìˆ˜ì¹˜ì™€ ì§€í‘œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰
            3. ë³€í™”ì˜ ì£¼ìš” ì›ì¸ê³¼ ì˜í–¥ ìš”ì†Œ ë¶„ì„
            4. í–¥í›„ ì „ë§ì´ë‚˜ ì˜ˆì¸¡ ì •ë³´ í¬í•¨ (ìˆëŠ” ê²½ìš°)
            5. ë¦¬í¬íŠ¸ì˜ í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œí•˜ì—¬ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€"""),
            HumanMessagePromptTemplate.from_template("""
            ì§ˆë¬¸: {query}
            
            ê´€ë ¨ ë¦¬í¬íŠ¸ ë‚´ìš©:
            {content}
            
            ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ì „ë¬¸ê°€ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.""")
        ])
        
        # ë¶„ì„ ì²´ì¸ ìƒì„±
        self.analysis_chain = self.analysis_prompt | self.llm


    # def create_self_query_retriever(self, k: int = 4) -> SelfQueryRetriever:
    #     """Self Query Retriever ìƒì„±"""
    #     try:
    #         prompt = get_query_constructor_prompt(
    #             document_contents=REPORT_DOCUMENT_DESCRIPTION,
    #             attribute_info=METADATA_FIELD_INFO,
    #             examples=SEARCH_EXAMPLES,
    #             allowed_comparators=["eq", "ne", "gt", "gte", "lt", "lte"],
    #             allowed_operators=["and", "or"]
    #         )

    #         parser = StructuredQueryOutputParser.from_components(
    #             allowed_comparators=["eq", "ne", "gt", "gte", "lt", "lte"],
    #             allowed_operators=["and", "or"]
    #         )

    #         query_constructor = prompt | self.llm | parser

    #         retriever = SelfQueryRetriever(
    #             query_constructor=query_constructor,
    #             vectorstore=self.vectorstore,
    #             structured_query_translator=ChromaTranslator(),
    #             search_kwargs={"k": k}
    #         )
            
    #         return retriever

    #     except Exception as e:
    #         error_msg = f"Self-query Retriever ìƒì„± ì˜¤ë¥˜: {str(e)}"
    #         self.logger.error(error_msg)
    #         raise Exception(error_msg)

    def get_retriever_results(self, query: str, filter: Optional[Dict[str, Any]] = None, k: int = 4) -> dict:
        try:
            print(f"\n=== ê²€ìƒ‰ ë° ì••ì¶• í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ===")
            print(f"ì…ë ¥ ì¿¼ë¦¬: {query}")
            print(f"í•„í„° ì¡°ê±´: {filter}")
            
            # 1. ì¿¼ë¦¬ ì¬ì‘ì„±
            enhanced_query = self.query_rewriter.rewrite_query(query)
            # ì¿¼ë¦¬ì—ì„œ ì–‘ìª½ ë”°ì˜´í‘œ ì œê±°
            enhanced_query = enhanced_query.strip('"')
            print(f"\nì¬ì‘ì„±ëœ ì¿¼ë¦¬: {enhanced_query}")
            
            # 2. ê²€ìƒ‰ ë° ì••ì¶• ì„¤ì •
            compressor = ReportLLMChainExtractor.from_llm(self.llm)
            compression_retriever = ContextualCompressionRetriever(
                base_compressor=compressor,
                base_retriever=self.vectorstore.as_retriever(
                    search_kwargs={"k": k, "filter": filter}
                )
            )
            
            # 3. ê²€ìƒ‰ ë° ì••ì¶• ìˆ˜í–‰
            compressed_docs = compression_retriever.get_relevant_documents(
                enhanced_query,
                callbacks=[SearchDebugHandler(), CompressionDebugHandler()]
            )
            
            if not compressed_docs:
                print("\nâŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return {}
            
            # ì‹œê°„ìˆœ ì •ë ¬
            sorted_docs = sorted(
                compressed_docs,
                key=lambda x: (x.metadata.get("year", 0), x.metadata.get("month", 0)),
                reverse=True
            )
            
            # 4. ë¬¸ì„œ ë‚´ìš© ê²°í•©
            combined_content = "\n\n".join(
                f"[{doc.metadata.get('year', 'ì•Œ ìˆ˜ ì—†ìŒ')}ë…„ {doc.metadata.get('month', 'ì•Œ ìˆ˜ ì—†ìŒ')}ì›”]\n{doc.page_content.strip()}"
                for doc in sorted_docs 
                if doc.page_content.strip()
            )
            
            # 5. LLMì„ í†µí•œ ë¶„ì„ ë° ë‹µë³€ ìƒì„±
            print("\n=== LLM ë¶„ì„ ì‹œì‘ ===")
            analysis_response = self.analysis_chain.invoke({
                "query": query,
                "content": combined_content
            })
            print("\nâœ… LLM ë¶„ì„ ì™„ë£Œ")
            
            return {
                "analysis": analysis_response.content,
                "raw_content": combined_content
            }
            
        except Exception as e:
            error_msg = f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            self.logger.error(error_msg)
            raise Exception(error_msg)