from typing import Type
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
from dotenv import load_dotenv
from selenium.common.exceptions import TimeoutException
import os
from typing import Optional, Dict, Any
from langchain_openai import ChatOpenAI
import pandas as pd
import os
import time
import re
from langchain.callbacks.manager import CallbackManagerForToolRun
from config.prompts import _STOCK_ANL_DESCRIPTION
api_key=os.getenv("OPENAI_API_KEY")
# API í‚¤ì™€ Gateway API í‚¤ë¥¼ ë„£ìŠµë‹ˆë‹¤.
os.environ["OPENAI_API_KEY"] = api_key





class StockAnalyzer:
    def __init__(self, api_key=None):
        load_dotenv()
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")

        if not self.api_key:
            raise ValueError("OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def clean_rate(self, rate):
        try:
            rate = re.sub(r'[^\d.-]', '', rate)
            return float(rate)
        except ValueError:
            #print(f"ë“±ë½ë¥  ë³€í™˜ ì‹¤íŒ¨: {rate}")
            return None

    def get_stock_data(self, corpname):
        #print("ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")
        driver = webdriver.Chrome(options=options)
        

        try:
            driver.get("https://tossinvest.com/")
            wait = WebDriverWait(driver, 5)

            # ê²€ìƒ‰ ì…ë ¥
            search_input = wait.until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, 'span.tw-1r5dc8g0'))
            )
            search_input.click()

            search_box = wait.until(
                EC.presence_of_element_located(
                    (By.CSS_SELECTOR, 'input[placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”"]')
                )
            )
            search_box.clear()
            search_box.send_keys(corpname)

            company_button = wait.until(
                EC.element_to_be_clickable((By.XPATH, "//div[@class='_1afau9j2']"))
            )
            company_button.click()

            time.sleep(1)
            daily_button = wait.until(
                EC.element_to_be_clickable((By.XPATH, '//button[@value="ì¼ë³„"]'))
            )
            daily_button.click()

            # ë°ì´í„° ìˆ˜ì§‘
            data = []
            collected_indices = set()

            while len(data) < 30: #### ì‚´í´ë³¼ ë‚ ì§œ ìˆ˜
                rows = driver.find_elements(By.XPATH, '//tr[@data-item-index]')

                for row in rows:
                    try:
                        data_index = int(row.get_attribute('data-item-index'))
                        if data_index in collected_indices:
                            continue

                        cells = row.find_elements(By.TAG_NAME,'td')
                        if len(cells) >= 3:
                            date = cells[0].text
                            closing_price = cells[1].text
                            change_rate = cells[2].text
                            data.append({
                                "ë‚ ì§œ": date,
                                "ì¢…ê°€": closing_price,
                                "ë“±ë½ë¥ ": change_rate
                            })
                            collected_indices.add(data_index)
                        driver.execute_script("arguments[0].scrollIntoView();", row)
                        time.sleep(0.05)
                    except Exception as e:
                        return e
                if len(data) >= 30: #ë‚ ì§œë²”ìœ„ì„¤ì •
                    break
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)

            if not data:
                #print("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return None

            df = pd.DataFrame(data)
            #print("ğŸ“ìˆ˜ì§‘ëœ ë°ì´í„° ì˜ˆì‹œ ì•ë¶€ë¶„:", df)
            # ë“±ë½ë¥  ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ê³  NaN ì œê±°
            df["ë“±ë½ë¥ "] = df["ë“±ë½ë¥ "].apply(self.clean_rate)  # ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜
            df = df.dropna(subset=["ë“±ë½ë¥ "])  # NaN ê°’ ì œê±°

            if df.empty:
                print("ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                return None
            # ì ˆëŒ€ê°’ ì—´ ì¶”ê°€
            df["ë“±ë½ë¥ _ì ˆëŒ€ê°’"] = df["ë“±ë½ë¥ "].abs()
            # ì–‘ìˆ˜ ë° ìŒìˆ˜ ë“±ë½ë¥  ìµœëŒ€ê°’ì˜ ë‚ ì§œ ì¶”ì¶œ
            positive_max_date = None
            negative_max_date = None

            positive_data = df[df["ë“±ë½ë¥ "] > 0]
            negative_data = df[df["ë“±ë½ë¥ "] < 0]

            if not positive_data.empty:
                positive_max_date = positive_data.loc[positive_data["ë“±ë½ë¥ "].idxmax(), "ë‚ ì§œ"]

            if not negative_data.empty:
                negative_max_date = negative_data.loc[negative_data["ë“±ë½ë¥ "].idxmin(), "ë‚ ì§œ"]


            #print("ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ div ë¡œë“œ ëŒ€ê¸° ì¤‘...")
            scrollable_div = wait.until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div[style*='overflow: auto']"))
            )

            # íˆ¬ìì ë°ì´í„° ì¶”ì¶œ
            personal_positive, foreign_positive, institution_positive = "N/A", "N/A", "N/A"
            personal_negative, foreign_negative, institution_negative = "N/A", "N/A", "N/A"

            last_row_count = 0
            scroll_step = 50

            while True:
                rows = scrollable_div.find_elements(By.CSS_SELECTOR, "tr.tw-mm1vn12.f2ww7n1._1p5yqoh0")
                #print(f"í˜„ì¬ {len(rows)}ê°œì˜ í–‰ì„ íƒìƒ‰ ì¤‘...")

                for index, row in enumerate(rows):
                    try:
                        date_element = row.find_element(
                            By.CSS_SELECTOR, "div.tw-kywygh2.tw-1h28joa4.tw-kywygh5"
                        )
                        date_text = date_element.text.strip()

                        # ì–‘ìˆ˜ ìµœëŒ€ ë‚ ì§œ ì²˜ë¦¬
                        if positive_max_date and positive_max_date in date_text:
                            #print(f"ì–‘ìˆ˜ ìµœëŒ€ ë‚ ì§œ '{positive_max_date}'ì™€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            personal_positive = row.find_element(By.CSS_SELECTOR, "td:nth-child(2) span.tw-1r5dc8g0").text.strip()
                            foreign_positive = row.find_element(By.CSS_SELECTOR, "td:nth-child(3) span.tw-1r5dc8g0").text.strip()
                            institution_positive = row.find_element(By.CSS_SELECTOR, "td:nth-child(4) span.tw-1r5dc8g0").text.strip()

                        # ìŒìˆ˜ ìµœëŒ€ ë‚ ì§œ ì²˜ë¦¬
                        if negative_max_date and negative_max_date in date_text:
                            #print(f"ìŒìˆ˜ ìµœëŒ€ ë‚ ì§œ '{negative_max_date}'ì™€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            personal_negative = row.find_element(By.CSS_SELECTOR, "td:nth-child(2) span.tw-1r5dc8g0").text.strip()
                            foreign_negative = row.find_element(By.CSS_SELECTOR, "td:nth-child(3) span.tw-1r5dc8g0").text.strip()
                            institution_negative = row.find_element(By.CSS_SELECTOR, "td:nth-child(4) span.tw-1r5dc8g0").text.strip()

                        # ë‘ ë‚ ì§œ ì •ë³´ê°€ ëª¨ë‘ ìˆ˜ì§‘ë˜ì—ˆìœ¼ë©´ ì¢…ë£Œ
                        if positive_max_date and negative_max_date and \
                        personal_positive != "N/A" and personal_negative != "N/A":
                            break

                    except Exception as e:
                        #print(f"í–‰ {index + 1}ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {e}")
                        continue

                driver.execute_script("arguments[0].scrollTop += arguments[1];", scrollable_div, scroll_step)
                time.sleep(1)

                new_rows = scrollable_div.find_elements(By.CSS_SELECTOR, "tr.tw-mm1vn12.f2ww7n1._1p5yqoh0")
                if len(new_rows) == last_row_count:
                    #print("ë” ì´ìƒ ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break
                last_row_count = len(new_rows)

            return {
                "ì–‘ìˆ˜_ìµœëŒ€": {
                    "ë‚ ì§œ": positive_max_date,
                    "ê°œì¸": personal_positive,
                    "ì™¸êµ­ì¸": foreign_positive,
                    "ê¸°ê´€": institution_positive,
                    "ë“±ë½ë¥ ": df.loc[df["ë‚ ì§œ"] == positive_max_date, "ë“±ë½ë¥ "].values[0]
                } if positive_max_date else None,
                "ìŒìˆ˜_ìµœëŒ€": {
                    "ë‚ ì§œ": negative_max_date,
                    "ê°œì¸": personal_negative,
                    "ì™¸êµ­ì¸": foreign_negative,
                    "ê¸°ê´€": institution_negative,
                    "ë“±ë½ë¥ ": df.loc[df["ë‚ ì§œ"] == negative_max_date, "ë“±ë½ë¥ "].values[0]
                } if negative_max_date else None
            }

        except Exception as e:
            #print(f"ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

        finally:
            driver.quit()

    def get_news_analysis(self, corpname, stock_data):
        #print("ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘")
        options = webdriver.ChromeOptions()
        options.add_argument("--headless")
        driver = webdriver.Chrome(options=options)

        try:
            analysis_results = {}

            for key, stock_info in {"ì–‘ìˆ˜_ìµœëŒ€": stock_data.get("ì–‘ìˆ˜_ìµœëŒ€"), "ìŒìˆ˜_ìµœëŒ€": stock_data.get("ìŒìˆ˜_ìµœëŒ€")}.items():
                if not stock_info:
                    analysis_results[key] = "í•´ë‹¹ ì¡°ê±´ì˜ ë‚ ì§œì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                    continue

                # ê° ì¡°ê±´ì— ë§ëŠ” ë‚ ì§œ ì„¤ì •
                target_date = stock_info['ë‚ ì§œ']
                #print(f"{key}ì˜ ê²€ìƒ‰ ë‚ ì§œ: {target_date}")  # ë””ë²„ê¹…ìš© ë‚ ì§œ í™•ì¸

                # URL ìƒì„±
                news_url = (
                    f"https://search.naver.com/search.naver?"
                    f"where=news&query={corpname}&sm=tab_opt&sort=0&photo=0&field=0"
                    f"&pd=3&ds=2024.{target_date}&de=2024.{target_date}&docid=&related=0"
                    f"&mynews=0&office_type=0&office_section_code=0&news_office_checked="
                    f"&nso=so%3Ar%2Cp%3Afrom{target_date.replace('.', '')}to{target_date.replace('.', '')}"
                    f"&is_sug_officeid=0&office_category=0&service_area=0"
                )

                # ë‰´ìŠ¤ ê²€ìƒ‰
                driver.get(news_url)

                wait = WebDriverWait(driver, 5)
                try:
                    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'a.news_tit')))
                except TimeoutException:
                    analysis_results[key] = "í•´ë‹¹ ë‚ ì§œì— ëŒ€í•œ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                    continue
                news_elements = driver.find_elements(By.CSS_SELECTOR, 'a.news_tit')

                # ë‰´ìŠ¤ ì œëª© ìˆ˜ì§‘
                titles = [news.text for news in news_elements[:15]]
                #print(f"{key} ê¸°ì¤€ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì œëª©:", titles)

                llm = ChatOpenAI(
                    model_name="gpt-4o",
                    openai_api_key=self.api_key
                )

                question = (
                    f"ë‹¤ìŒ ë‰´ìŠ¤ ì œëª©ë“¤ {titles}ì„ ë°”íƒ•ìœ¼ë¡œ {corpname} ì£¼ì‹ì´ ë³€ë™í•œ ì´ìœ ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”. "
                    f"í•´ë‹¹ ë‚ ì§œ({target_date}) ê¸°ì¤€ ê°œì¸íˆ¬ìì: {stock_info['ê°œì¸']}, "
                    f"ì™¸êµ­ì¸íˆ¬ìì: {stock_info['ì™¸êµ­ì¸']}, ê¸°ê´€íˆ¬ìì: {stock_info['ê¸°ê´€']}ì˜ íˆ¬ì ë™í–¥ë„ í•¨ê»˜ ê³ ë ¤í•´ì£¼ì„¸ìš”. "
                    f"ë“±ë½ë¥ : {stock_info['ë“±ë½ë¥ ']}ì´ {'ì–‘ìˆ˜' if key == 'ì–‘ìˆ˜_ìµœëŒ€' else 'ìŒìˆ˜'}ë©´ "
                    f"{'ê¸ì •ì ì¸' if key == 'ì–‘ìˆ˜_ìµœëŒ€' else 'ë¶€ì •ì ì¸'} ì´ìŠˆë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
                )

                response = llm(question)
                analysis_results[key] = response.content

            return analysis_results

        except Exception as e:
            #print(f"ë‰´ìŠ¤ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

        finally:
            driver.quit()

    def analyze_stock(self, corpname):
        # ì „ì²´ ì£¼ì‹ ë¶„ì„ ì‹œì‘
        stock_data = self.get_stock_data(corpname)
        if not stock_data:
            #print("ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        news_analysis = self.get_news_analysis(corpname, stock_data)
        return {
            "ì–‘ìˆ˜_ìµœëŒ€_ë¶„ì„": news_analysis.get("ì–‘ìˆ˜_ìµœëŒ€"),
            "ìŒìˆ˜_ìµœëŒ€_ë¶„ì„": news_analysis.get("ìŒìˆ˜_ìµœëŒ€"),
            "ì£¼ì‹_ë°ì´í„°": stock_data
        }


class StockAnalyzerInputs(BaseModel):
    query: str = Field(..., description="ê²€ìƒ‰í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥")
    company: str = Field(..., description="íšŒì‚¬ëª…")
    year: int = Field(..., description="ì—°ë„")

class StockAnalyzerTool(BaseTool):
    name: str = "StockAnalyzerTool"
    description: str = _STOCK_ANL_DESCRIPTION
    args_schema: Type[BaseModel] = StockAnalyzerInputs

    def _run(self, query: str, company:str, year:int, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:
        try:              
            filter_dict={}
            filter_dict["year"] = year
            filter_dict["companyName"] = company
            filter_dict["query"] =query
                    
            # StockAnalyzer ì‹¤í–‰
            analyzer = StockAnalyzer()
            result = analyzer.analyze_stock(filter_dict["companyName"])

            if not result:
                return "ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜ ë¶„ì„í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

            stock_data = result.get('ì£¼ì‹_ë°ì´í„°', {})
            news_analysis = {
                "ì–‘ìˆ˜_ìµœëŒ€": result.get('ì–‘ìˆ˜_ìµœëŒ€_ë¶„ì„', "ì–‘ìˆ˜ ìµœëŒ€ ë“±ë½ë¥  ë‚ ì§œì— ëŒ€í•œ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."),
                "ìŒìˆ˜_ìµœëŒ€": result.get('ìŒìˆ˜_ìµœëŒ€_ë¶„ì„', "ìŒìˆ˜ ìµœëŒ€ ë“±ë½ë¥  ë‚ ì§œì— ëŒ€í•œ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            }

            # ì£¼ì‹ ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬
            if not stock_data:
                return "ì£¼ì‹ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            # ì–‘ìˆ˜ ìµœëŒ€ ë° ìŒìˆ˜ ìµœëŒ€ ì£¼ì‹ ë°ì´í„° ë¬¸ìì—´ í¬ë§·íŒ…
            positive_stock_data = stock_data.get("ì–‘ìˆ˜_ìµœëŒ€", None)
            negative_stock_data = stock_data.get("ìŒìˆ˜_ìµœëŒ€", None)

            positive_data_str = (
                f"=== ì–‘ìˆ˜ ìµœëŒ€ ë“±ë½ë¥  ===\n"
                f"ë‚ ì§œ: {positive_stock_data.get('ë‚ ì§œ', 'N/A')}\n"
                f"ê°œì¸: {positive_stock_data.get('ê°œì¸', 'N/A')}\n"
                f"ì™¸êµ­ì¸: {positive_stock_data.get('ì™¸êµ­ì¸', 'N/A')}\n"
                f"ê¸°ê´€: {positive_stock_data.get('ê¸°ê´€', 'N/A')}\n"
                f"ë“±ë½ë¥ : {positive_stock_data.get('ë“±ë½ë¥ ', 'N/A')}\n"
            ) if positive_stock_data else "ì–‘ìˆ˜ ìµœëŒ€ ë“±ë½ë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

            negative_data_str = (
                f"=== ìŒìˆ˜ ìµœëŒ€ ë“±ë½ë¥  ===\n"
                f"ë‚ ì§œ: {negative_stock_data.get('ë‚ ì§œ', 'N/A')}\n"
                f"ê°œì¸: {negative_stock_data.get('ê°œì¸', 'N/A')}\n"
                f"ì™¸êµ­ì¸: {negative_stock_data.get('ì™¸êµ­ì¸', 'N/A')}\n"
                f"ê¸°ê´€: {negative_stock_data.get('ê¸°ê´€', 'N/A')}\n"
                f"ë“±ë½ë¥ : {negative_stock_data.get('ë“±ë½ë¥ ', 'N/A')}\n"
            ) if negative_stock_data else "ìŒìˆ˜ ìµœëŒ€ ë“±ë½ë¥  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

            # ìµœì¢… ê²°ê³¼ ë¬¸ìì—´ ì¡°í•©
            final_str = (
                f"ë§¤ì¹­ëœ ê¸°ì—…ëª…: {filter_dict['companyName']}\n\n"
                f"{positive_data_str}\n"
                f"=== ì–‘ìˆ˜ ìµœëŒ€ ë‰´ìŠ¤ ë¶„ì„ ===\n{news_analysis['ì–‘ìˆ˜_ìµœëŒ€']}\n\n"
                f"{negative_data_str}\n"
                f"=== ìŒìˆ˜ ìµœëŒ€ ë‰´ìŠ¤ ë¶„ì„ ===\n{news_analysis['ìŒìˆ˜_ìµœëŒ€']}\n"
            )

            return final_str
        except Exception as e:
            return f"Unexpected error occurred: {e}"