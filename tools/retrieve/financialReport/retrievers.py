"""
ë‹¤ì–‘í•œ ê²€ìƒ‰ê¸°(Retriever) êµ¬í˜„ ëª¨ë“ˆ
"""
import os
import OpenDartReader
from typing import List, Optional, Dict, Any, Callable, Iterable, Sequence, Tuple
from langchain_core.documents import Document
from langchain_core.language_models import BaseLanguageModel
from langchain_openai import ChatOpenAI
from langchain_community.chat_models import ChatClovaX
from langchain.retrievers.document_compressors import LLMChainExtractor
from langchain.retrievers import ContextualCompressionRetriever
from langchain_core.output_parsers import StrOutputParser
from tools.retrieve.financialReport.utils import format_table
from tools.retrieve.financialReport.prompts import (
    REWRITE_PROMPT,
    FINAL_SUMMARY_PROMPT,
    EXTRACT_PROMPT,
    DEFAULT_TITLE,
)
from langchain_core.callbacks import BaseCallbackHandler
from uuid import UUID
from langchain_core.runnables import RunnableLambda
from langchain.prompts import PromptTemplate
from typing import Callable
from tools.retrieve.financialReport.korean_nlp import KoreanTextAnalyzer

korean_nlp = KoreanTextAnalyzer()

class CustomLLMChainExtractor(LLMChainExtractor):
    """ë©”íƒ€ë°ì´í„°ì˜ í…Œì´ë¸” ì •ë³´ë„ ê³ ë ¤í•˜ëŠ” ë¬¸ì„œ ì••ì¶•ê¸°"""
    
    @classmethod
    def from_llm(
        cls,
        llm: BaseLanguageModel,
        prompt: Optional[PromptTemplate] = None,
        get_input: Optional[Callable[[str, Document], str]] = None,
    ) -> "CustomLLMChainExtractor":
        """LLMìœ¼ë¡œë¶€í„° ì´ˆê¸°í™”"""
        
        _prompt = EXTRACT_PROMPT
        
        def custom_get_input(query: str, doc: Document) -> dict:
            """ë¬¸ì„œì™€ í…Œì´ë¸” ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ì…ë ¥ ìƒì„±"""
            table_info = ""
            if "table" in doc.metadata:
                table_info = format_table(doc.metadata["table"])
            
            return {
                "query": query,
                "page_content": doc.page_content,
                "table_info": table_info
            }
        
        _get_input = custom_get_input if get_input is None else get_input
        
        if _prompt.output_parser is not None:
            parser = _prompt.output_parser
        else:
            parser = StrOutputParser()
            
        llm_chain = _prompt | llm | parser
        return cls(llm_chain=llm_chain, get_input=_get_input)
    
class DocumentContentParser:
    """ë¬¸ì„œ ë‚´ìš©ì„ íŒŒì‹±í•˜ê³  ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    @staticmethod
    def combine_page_contents(docs: List[Document]) -> str:
        """Document ë¦¬ìŠ¤íŠ¸ì˜ ëª¨ë“  page_contentë¥¼ ê²°í•©"""
        return " ".join(doc.page_content.strip().strip("\n").strip() for doc in docs)
    
    @staticmethod
    def combine_with_metadata(docs: List[Document]) -> List[dict]:
        """Document ë¦¬ìŠ¤íŠ¸ì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ ê²°í•©"""
        return [
            {
                "content": doc.page_content,
                "metadata": doc.metadata
            } for doc in docs
        ]


class RewriteDebugHandler(BaseCallbackHandler):
    """ì§ˆë¬¸ ì¬êµ¬ì„± ê³¼ì •ì˜ ë””ë²„ê¹…ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    def on_chain_end(
        self, 
        outputs: Any, 
        *, 
        run_id: UUID, 
        parent_run_id: UUID | None = None,
        **kwargs: Any
    ) -> Any:
        """ì²´ì¸ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        if isinstance(outputs, str):
            print("\n" + "="*50)
            print("ğŸ“ ì§ˆë¬¸ ì¬êµ¬ì„± ê²°ê³¼")
            print("="*50)
            print(f"ì¬êµ¬ì„±ëœ ì§ˆë¬¸: {outputs}")
            print("="*50 + "\n")

class QueryConstructorDebugHandler(BaseCallbackHandler):
    """êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ìƒì„± ê³¼ì •ì˜ ë””ë²„ê¹…ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬"""
    def on_chain_end(
        self, 
        outputs: Any, 
        *, 
        run_id: UUID, 
        parent_run_id: UUID | None = None,
        **kwargs: Any
    ) -> Any:
        """ì²´ì¸ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        if hasattr(outputs, "filter") or hasattr(outputs, "query"):
            print("\n" + "="*50)
            print("ğŸ” êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ ìƒì„± ê²°ê³¼")
            print("="*50)
            filter_condition = getattr(outputs, "filter", None)
            query = getattr(outputs, "query", None)
            print(f"í•„í„° ì¡°ê±´: {filter_condition}")
            print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
            print("="*50 + "\n")

    def on_retriever_start(
        self, 
        serialized: Dict[str, Any],
        query: str,
        *,
        run_id: UUID,
        parent_run_id: UUID | None = None,
        tags: List[str] | None = None,
        metadata: Dict[str, Any] | None = None,
        **kwargs: Any
    ) -> Any:
        """ê²€ìƒ‰ ì‹œì‘ ì‹œ í˜¸ì¶œ"""
        print("\n" + "="*50)
        print("ğŸš€ ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘")
        print("="*50)
        print(f"ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        print("="*50 + "\n")

    def on_retriever_end(
        self,
        documents: Sequence[Document],
        *,
        run_id: UUID,
        parent_run_id: UUID | None = None,
        **kwargs: Any
    ) -> Any:
        """ê²€ìƒ‰ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
        print("\n" + "="*50)
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ - {len(documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
        print("="*50)
        for i, doc in enumerate(documents, 1):
            print(f"\nğŸ“„ ë¬¸ì„œ {i}:")
            print(f"ë‚´ìš©: {doc.page_content[:150]}...")
            print(f"ë©”íƒ€ë°ì´í„°: {doc.metadata}")
        print("="*50 + "\n")

    def on_retriever_error(
        self,
        error: BaseException,
        *,
        run_id: UUID,
        parent_run_id: UUID | None = None,
        **kwargs: Any
    ) -> Any:
        """ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ ì‹œ í˜¸ì¶œ"""
        print("\n" + "="*50)
        print("âŒ ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ")
        print("="*50)
        print(f"ì˜¤ë¥˜ ë‚´ìš©: {str(error)}")
        print("="*50 + "\n")

class RetrievalManager:
    """ê²€ìƒ‰ê¸° ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, vectorstore, llm: Optional[BaseLanguageModel] = None):
        self.vectorstore = vectorstore
        self.gpt_4o = ChatOpenAI(
            model="chatgpt-4o-latest",
            temperature=0,
        )
        self.gpt_4_turbo = ChatOpenAI(
            model="gpt-4-turbo",
            temperature=0,
        )
        self.gpt_4o_mini = ChatOpenAI(
            model="gpt-4o-mini-2024-07-18",
            temperature=0,
        )
        self.gpt_35_turbo = ChatOpenAI(
            model="gpt-3.5-turbo-0125",
            temperature=0,
        )
        self.clova_x = ChatClovaX(
            model="HCX-003",
            temperature=0.1,
            include_ai_filters=False,
        )
        self.korean_nlp = korean_nlp
        self.rewrite_callbacks = [RewriteDebugHandler()]
        self.query_constructor_callbacks = [QueryConstructorDebugHandler()]
        self.dart = OpenDartReader("4925a6e6e69d8f9138f4d9814f56f371b2b2079a")

    def _create_parse_runnable(self):
        """íŒŒì‹±ì„ ìœ„í•œ Runnable ìƒì„±"""
        return RunnableLambda(
            lambda x: x.strip()  # ì•ë’¤ ê³µë°± ì œê±°
                .strip('"')      # ë”°ì˜´í‘œ ì œê±°
                .strip('\\')     
                .strip('\\n')    # ê°œí–‰ë¬¸ì ì œê±°
                .rstrip('*')     # ëì˜ ë³„í‘œ ì œê±°
                .strip()         # ìµœì¢… ê³µë°± ì œê±°
        ).with_config({"name": "ParseChain", "callbacks": self.rewrite_callbacks})
    
    def _create_rewrite_chain(self):
        """ì¿¼ë¦¬ ì¬ì‘ì„± ì²´ì¸ ìƒì„±"""
        self._parse = self._create_parse_runnable()
        chain = (REWRITE_PROMPT | self.gpt_4o_mini | StrOutputParser() | self._parse)
        return chain
    
    def rewrite_query(self, query: str, title: str = "") -> str:
        """ì¿¼ë¦¬ ì¬ì‘ì„± ìˆ˜í–‰"""
        if not title:
            title = DEFAULT_TITLE
        rewriter = self._create_rewrite_chain()
        rewrite_query = rewriter.invoke({"query": query, "title": title})
        return rewrite_query
    
    def create_compression_retriever(self, base_retriever) -> ContextualCompressionRetriever:
        """ì••ì¶• ê²€ìƒ‰ê¸° ìƒì„±"""
        compressor = CustomLLMChainExtractor.from_llm(
            self.clova_x,
            )
        return ContextualCompressionRetriever(
            base_compressor=compressor,
            base_retriever=base_retriever,
        )
    
    def create_retriever(self, k: int = 4, use_mmr: bool = True, metadata_filter: Optional[Dict[str, Any]] = None) -> Any:
        """ë©”íƒ€ë°ì´í„° í•„í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²€ìƒ‰ê¸° ìƒì„±
        
        Args:
            k (int): ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            use_mmr (bool): MMR ì‚¬ìš© ì—¬ë¶€
            metadata (Optional[Dict]): ë©”íƒ€ë°ì´í„° í•„í„° (ì˜ˆ: {"companyName": "ì‚¼ì„±ì „ì", "year": 2023})
        """
        # ë©”íƒ€ë°ì´í„°ë¥¼ ChromaDB í•„í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        filter_dict = {}
        if metadata_filter:
            filter_conditions = []
            if 'companyName' in metadata_filter:
                filter_conditions.append({"companyName": metadata_filter['companyName']})
            if 'year' in metadata_filter:
                filter_conditions.append({"year": metadata_filter['year']})
            if filter_conditions:
                filter_dict = {"$and": filter_conditions} if len(filter_conditions) > 1 else filter_conditions[0]
        
        search_kwargs = {
            "k": k,
            "filter": filter_dict,
            "fetch_k": k * 4 if use_mmr else k,
            "lambda_mult": 0.65 if use_mmr else None
        }
        
        if use_mmr:
            retriever = self.vectorstore.as_retriever(
                search_type="mmr",
                search_kwargs=search_kwargs
            )
        else:
            retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs=search_kwargs
            )
                
        return retriever

    def get_retriever_results(self, query: str, k: int = 4, rewrite: bool = True, metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ê²€ìƒ‰ê¸° ê²°ê³¼ ë°˜í™˜"""
        from tools.retrieve.financialReport.prompts import output_parser
        rcept_no_title = ""
        rcept_no = self.dart.finstate(metadata['companyName'], metadata['year'], reprt_code="11011")
        if not rcept_no.empty:
            rcept_no = rcept_no['rcept_no'].unique()[0]
            rcept_no_title = '\n'.join(self.dart.sub_docs(rcept_no)['title'].tolist())

        if rewrite:
            query = self.rewrite_query(query, rcept_no_title)
        
        final_summary_chain = (
            FINAL_SUMMARY_PROMPT 
            | self.gpt_4o
            | output_parser
        )

        def perform_search(metadata_filter):
            base_retriever = self.create_retriever(
                k=k, 
                metadata_filter=metadata_filter
            )
            compression_retriever = self.create_compression_retriever(base_retriever)
            return compression_retriever.invoke(query)

        # ì²« ë²ˆì§¸ ê²€ìƒ‰ ìˆ˜í–‰
        results_docs = perform_search(metadata)
        
        # 2024ë…„ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê³ , í˜„ì¬ ì—°ë„ê°€ 2024ë…„ì¸ ê²½ìš° 2023ë…„ ë°ì´í„°ë¡œ ì¬ê²€ìƒ‰
        if (not results_docs and 
            metadata and 
            metadata.get('year') == 2024 or metadata.get('year') == 2025):
            metadata_2023 = metadata.copy()
            metadata_2023['year'] = 2023
            results_docs = perform_search(metadata_2023)
            if results_docs:
                # 2023ë…„ ë°ì´í„°ë¥¼ ì°¾ì•˜ë‹¤ëŠ” ë©”ì‹œì§€ ì¶”ê°€
                prefix_message = f"[{metadata.get('year')}ë…„ ë°ì´í„°ê°€ ì—†ì–´ {metadata.get('year')-1}ë…„ ë°ì´í„°ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤]\n"
        else:
            prefix_message = ""
        
        # ë„íë¨¼íŠ¸ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ key_information êµ¬ì„±
        report_results = {
            "output": "",
            "key_information": []
        }
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ê²°í•©
        combined_content = []
        
        for doc in results_docs:
            referenced_content = doc.page_content
            if referenced_content and referenced_content.strip():
                metadata = doc.metadata
                report_results["key_information"].append({
                    "tool": "ì‚¬ì—…ë³´ê³ ì„œ",
                    "needed_information": metadata.get("needed_information", "ë¬¸ì„œ ì •ë³´"),
                    "referenced_content": referenced_content,
                    "page_number": metadata.get("page_number", "N/A"),
                    "filename": metadata.get("filename", "unknown"),
                    "link": metadata.get("link", "N/A")
                })
                combined_content.append(referenced_content)
        
        # ê²°í•©ëœ ë‚´ìš©ì„ outputì— ì„¤ì •
        report_results["output"] = prefix_message + ("\n".join(combined_content) if combined_content else "ì‚¬ì—…ë³´ê³ ì„œ ì—ì´ì „íŠ¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìµœì¢… ì…ë ¥ êµ¬ì„±
        final_input = {
            "query": query,
            "search_results": report_results,
        }
        
        # ìµœì¢… ìš”ì•½ ìƒì„±
        results = final_summary_chain.invoke(final_input)
        results['output'] = prefix_message + self.korean_nlp.normalize_text(results['output'])
        return results
