import logging
import os
from typing import Set,  List
from typing import Any, Optional
import json
import pandas as pd
from langchain_core.output_parsers import BaseOutputParser
from langchain_core.documents import Document
import FinanceDataReader as fdr

def create_document_merge_chain():
    def merge_and_restructure_documents(docs: List[Document]) -> List[Document]:
        merged_docs = []
        current_text = ""
        current_table = ""
        current_metadata = {}
        MAX_DOC_LENGTH = 2000

        for doc in docs:
            # í…Œì´ë¸”ê³¼ í…ìŠ¤íŠ¸ ë¶„ë¦¬
            table_content = ""
            if 'table' in doc.metadata:
                table_content = format_table(doc.metadata['table'])
            
            # í˜„ì¬ ë¬¸ì„œì˜ ë‚´ìš© êµ¬ì„±
            new_text = doc.page_content.strip() if doc.page_content else ""
            new_table = table_content if table_content else ""
            
            # ë³‘í•©ë  ì „ì²´ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
            merged_text = ""
            if current_text or new_text:
                merged_text = "ê´€ë ¨ í…ìŠ¤íŠ¸:\n" + \
                    ((current_text + "\n" + new_text) if current_text and new_text 
                     else (current_text or new_text))
            
            merged_table = ""
            if current_table or new_table:
                merged_table = "ê´€ë ¨ í…Œì´ë¸”:\n" + \
                    ((current_table + "\n" + new_table) if current_table and new_table 
                     else (current_table or new_table))
            
            combined_content = "\n\n".join(filter(None, [merged_text, merged_table]))

            # ê¸¸ì´ ì²´í¬ ë° ë¬¸ì„œ ìƒì„±
            if len(combined_content) > MAX_DOC_LENGTH:
                if current_text or current_table:
                    # í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ ë‚´ìš©ìœ¼ë¡œ ë¬¸ì„œ ìƒì„±
                    current_content = ""
                    if current_text:
                        current_content += "ê´€ë ¨ í…ìŠ¤íŠ¸:\n" + current_text
                    if current_table:
                        if current_content:
                            current_content += "\n\n"
                        current_content += "ê´€ë ¨ í…Œì´ë¸”:\n" + current_table
                    
                    merged_docs.append(Document(
                        page_content=current_content,
                        metadata=current_metadata.copy()
                    ))
                
                # ìƒˆë¡œìš´ ë‚´ìš©ìœ¼ë¡œ ì´ˆê¸°í™”
                current_text = new_text
                current_table = new_table
                current_metadata = {k:v for k,v in doc.metadata.items() if k != 'table'}
            else:
                # ë‚´ìš© ëˆ„ì 
                current_text = (current_text + "\n" + new_text) if current_text and new_text else (current_text or new_text)
                current_table = (current_table + "\n" + new_table) if current_table and new_table else (current_table or new_table)
                current_metadata.update({k:v for k,v in doc.metadata.items() if k != 'table'})

        # ë§ˆì§€ë§‰ ë‚¨ì€ ë‚´ìš© ì²˜ë¦¬
        if current_text or current_table:
            final_content = ""
            if current_text:
                final_content += "ê´€ë ¨ í…ìŠ¤íŠ¸:\n" + current_text
            if current_table:
                if final_content:
                    final_content += "\n\n"
                final_content += "ê´€ë ¨ í…Œì´ë¸”:\n" + current_table
                
            merged_docs.append(Document(
                page_content=final_content,
                metadata=current_metadata
            ))

        return merged_docs

    return merge_and_restructure_documents

def get_company_names_from_files(data_dir: str = "data/") -> Set[str]:
    """
    data/all_company_names.json íŒŒì¼ì—ì„œ ê¸°ì—…ëª… ëª©ë¡ì„ ë¶ˆëŸ¬ì˜´
    
    Args:
        data_dir: ë°ì´í„° í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: "data/")
        
    Returns:
        ê¸°ì—…ëª… ì§‘í•© (Set)
    """
    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ json íŒŒì¼ ê²½ë¡œ ìƒì„±

    # ./data/all_company_names.json ì„ ì°¾ì•„ì˜¤ëŠ” ê²ƒì„ 
    json_path = os.path.join(os.getcwd(), data_dir, "all_company_names.json")
    
    # íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ë¹ˆ ì§‘í•© ë°˜í™˜
    if not os.path.exists(json_path):
        print(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {json_path}")
        return set()
    logging.info(f"íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤: {json_path}")
    # JSON íŒŒì¼ì—ì„œ ê¸°ì—…ëª… ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            company_names = set(data.get('companies', []))
        return company_names
    except Exception as e:
        print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return set()

def format_table(table_data: Any) -> str:
    """í…Œì´ë¸” ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not table_data:
        return table_data
            
    try:
        # JSON ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
        if isinstance(table_data, str):
            if table_data.startswith('"table":'):
                table_data = table_data.replace('"table":', '').strip()
            try:
                # JSON íŒŒì‹± ì‹œë„
                table_data = json.loads(table_data)
            except json.JSONDecodeError:
                # ê¸°ì¡´ íŒŒì‹± ë¡œì§ ìœ ì§€
                cleaned = table_data.strip('[]')
                rows = [row.strip().strip('[]').split(',') for row in cleaned.split('],[')]
                table_data = [[item.strip().strip("'\"") for item in row] for row in rows]
        
        if isinstance(table_data, list) and len(table_data) > 0:
            # ì²« ë²ˆì§¸ í–‰ì´ ë¬¸ìì—´ì¸ ê²½ìš° ë¶„ë¦¬
            if isinstance(table_data[0], str):
                table_data = [row.strip('[]').split(',') for row in table_data]
                table_data = [[item.strip().strip("'\"") for item in row] for row in table_data]
            
            # DataFrame ìƒì„± ë° ë¬¸ìì—´ë¡œ ë³€í™˜
            df = pd.DataFrame(table_data)
            if len(df) > 0:
                # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©
                df.columns = df.iloc[0]
                df = df.iloc[1:]
                # TH ì ‘ë‘ì‚¬ ì œê±°
                df.columns = [str(col).replace('TH', '') for col in df.columns]
            return df.to_string(index=False)
    except Exception as e:
        print(f"Error: {e}")  # ë””ë²„ê¹…ìš©
        return str(table_data)
    
    return str(table_data)


# def format_table(table_data: Any) -> str:
#     if not table_data:
#         return table_data
            
#     try:
#         if isinstance(table_data, list) and len(table_data) > 0:
#             # ëª¨ë“  í–‰ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (2ì°¨ì› í…Œì´ë¸”)
#             if all(isinstance(row, list) for row in table_data):
#                 # ê° ì—´ì˜ ìµœëŒ€ ë„ˆë¹„ ê³„ì‚°
#                 col_widths = []
#                 for col in zip(*table_data):
#                     col_widths.append(max(len(str(cell)) for cell in col))
                
#                 # í¬ë§·íŒ…ëœ í–‰ ìƒì„±
#                 formatted_rows = []
#                 for row in table_data:
#                     formatted_cells = [
#                         str(cell).ljust(width) 
#                         for cell, width in zip(row, col_widths)
#                     ]
#                     formatted_rows.append(" ".join(formatted_cells))
                
#                 return "\n".join(formatted_rows)
#             else:
#                 # 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
#                 max_key_width = max(len(str(table_data[i])) for i in range(0, len(table_data), 2))
#                 formatted_rows = []
#                 for i in range(0, len(table_data), 2):
#                     if i + 1 < len(table_data):
#                         key = str(table_data[i]).ljust(max_key_width)
#                         value = str(table_data[i+1])
#                         formatted_rows.append(f"{key} | {value}")
#                 return "\n".join(formatted_rows)
                
#     except Exception as e:
#         print(f"Error in format_table: {e}")
#         return str(table_data)
    
#     return str(table_data)

class LineListOutputParser(BaseOutputParser[List[str]]):
    """Output parser for a list of lines."""

    def parse(self, text: str) -> List[str]:
        lines = text.strip().split("\n")
        return list(filter(None, lines))  # Remove empty lines


def pretty_print_docs(documents: List[Document]) -> None:
    """ê²€ìƒ‰ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
    print("\n" + "="*80)
    print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ - ì´ {len(documents)}ê°œ ë¬¸ì„œ")
    print("="*80)
    
    for i, doc in enumerate(documents, 1):
        print(f"\nğŸ“‘ ë¬¸ì„œ {i}")
        print("-"*80)
        # ë³¸ë¬¸ ë‚´ìš© ì¶œë ¥
        print("\nğŸ“ ë³¸ë¬¸:")
        content = doc.page_content
        if len(content) > 200:
            content = content[:200] + "..."
        print(content, '\n')
        
        # ë©”íƒ€ë°ì´í„° ì¶œë ¥
        print("ğŸ“Œ ë©”íƒ€ë°ì´í„°:")
        metadata = doc.metadata
        for key, value in metadata.items():
            # í…Œì´ë¸” ë°ì´í„°ëŠ” íŠ¹ë³„ ì²˜ë¦¬
            if key == 'table':
                print(f"  â–ª {key}: [í‘œ ë°ì´í„° í¬í•¨]")
                continue
            # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì¶•ì•½
            if isinstance(value, str) and len(value) > 100:
                value = value[:100] + "..."
            print(f"  â–ª {key}: {value}")
        
        # í…Œì´ë¸” ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í‘œ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
        if 'table' in metadata and metadata['table']:
            print("\nğŸ“Š í‘œ ë°ì´í„°:")
            try:
                formatted_table = format_table(metadata['table'])
                if len(formatted_table) > 500:
                    formatted_table = formatted_table[:500] + "..."
                print(formatted_table)
            except:
                print("  [í‘œ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨]")
        
        print("-"*80 + "\n")


def preprocess_financial_df(df):
    # 1. ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
    columns_to_drop = [
        'ord',
        'fs_nm',
        'bfefrmtrm_nm', 'frmtrm_nm',
        'frmtrm_add_amount',
        'corp_code', 'stock_code', 'reprt_code',
        'fs_div', 'sj_div', 'account_id',
        'account_detail', 'thstrm_add_amount',
    ]
    
    # ì—°ë„ë³„ ë°ì´í„° ì •ë¦¬
    df['bsns_year'] = pd.to_numeric(df['bsns_year'], errors='coerce')
    latest_year = df['bsns_year'].max()
    # ì „ê¸°, ì „ì „ê¸° ê¸ˆì•¡ì„ ìˆ«ìë¡œ ë³€í™˜
    df['frmtrm_amount'] = pd.to_numeric(df['frmtrm_amount'], errors='coerce')
    df['bfefrmtrm_amount'] = pd.to_numeric(df['bfefrmtrm_amount'], errors='coerce')
    df['thstrm_amount'] = pd.to_numeric(df['thstrm_amount'], errors='coerce')

    # ì—°ë„ë³„ë¡œ ìˆœíšŒí•˜ë©´ì„œ ë°ì´í„° ì •ì •
    years = sorted(df['bsns_year'].unique(), reverse=True)
    
    for i in range(len(years)):
        current_year = years[i]
        current_year_data = df[df['bsns_year'] == current_year]
        
        # ë‹¤ìŒ ì—°ë„ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
        if i < len(years)-1:
            next_year = years[i+1]
            next_year_data = df[df['bsns_year'] == next_year]
            
            # í˜„ì¬ ì—°ë„ì˜ ì „ê¸° ê¸ˆì•¡ê³¼ ë‹¤ìŒ ì—°ë„ì˜ ë‹¹ê¸° ê¸ˆì•¡ ë¹„êµ
            for _, row in current_year_data.iterrows():
                account = row['account_nm']
                prev_amount = row['frmtrm_amount']
                
                next_year_row = next_year_data[next_year_data['account_nm'] == account]
                if not next_year_row.empty:
                    current_amount = next_year_row.iloc[0]['thstrm_amount']
                    if pd.notna(current_amount) and (pd.isna(prev_amount) or prev_amount != current_amount):
                        df.loc[(df['bsns_year'] == current_year) & (df['account_nm'] == account), 'frmtrm_amount'] = current_amount
            
            # í˜„ì¬ ì—°ë„ì˜ ì „ì „ê¸° ê¸ˆì•¡ê³¼ ë‹¤ìŒ ì—°ë„ì˜ ì „ê¸° ê¸ˆì•¡ ë¹„êµ
            for _, row in current_year_data.iterrows():
                account = row['account_nm']
                prev_prev_amount = row['bfefrmtrm_amount']
                
                next_year_row = next_year_data[next_year_data['account_nm'] == account]
                if not next_year_row.empty:
                    prev_amount = next_year_row.iloc[0]['frmtrm_amount']
                    if pd.notna(prev_amount) and (pd.isna(prev_prev_amount) or prev_prev_amount != prev_amount):
                        df.loc[(df['bsns_year'] == current_year) & (df['account_nm'] == account), 'bfefrmtrm_amount'] = prev_amount

    df = df.drop(columns=columns_to_drop, errors='ignore')
    
    # 2. ì—´ ì´ë¦„ í•œê¸€ë¡œ ë³€ê²½
    column_mapping = {
        'rcept_no': 'ì ‘ìˆ˜ë²ˆí˜¸',
        'corp_code': 'ê¸°ì—…ì½”ë“œ',
        'stock_code': 'ì¢…ëª©ì½”ë“œ',
        'reprt_code': 'ë³´ê³ ì„œì½”ë“œ',
        'account_nm': 'ê³„ì •ëª…',
        'fs_div': 'ì¬ë¬´ì œí‘œêµ¬ë¶„',  # CFS/OFS
        'sj_div': 'ì¬ë¬´ì œí‘œì¢…ë¥˜',  # BS/IS
        'sj_nm': 'ì¬ë¬´ì œí‘œëª…',
        'thstrm_dt': 'ë‹¹ê¸°ì¼ì',
        'thstrm_nm': 'ë‹¹ê¸°ëª…',
        'thstrm_amount': 'ë‹¹ê¸°ê¸ˆì•¡',
        'frmtrm_dt': 'ì „ê¸°ì¼ì',
        'frmtrm_amount': 'ì „ê¸°ê¸ˆì•¡',
        'bfefrmtrm_dt': 'ì „ì „ê¸°ì¼ì',
        'bfefrmtrm_amount': 'ì „ì „ê¸°ê¸ˆì•¡',
        'thstrm_add_amount': 'ë‹¹ê¸°ëˆ„ì ê¸ˆì•¡',
        'bsns_year': 'ì—°ë„',
        'currency': 'ë‹¨ìœ„',
    }
    
    df = df.rename(columns=column_mapping)
    
    return df

def update_kospi_list():
    """KOSPI ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ìµœì‹ í™”í•˜ì—¬ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # FinanceDataReaderë¥¼ ì‚¬ìš©í•˜ì—¬ KOSPI ìƒì¥ ì¢…ëª© ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì‹œê°€ì´ì•¡ ë‚´ë¦¼ì°¨ìˆœ)
        kospi = fdr.StockListing('KOSPI-DESC')
        
        # ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë³€ê²½
        kospi_list = kospi.rename(columns={
            'Code': 'ì¢…ëª©ì½”ë“œ',
            'Name': 'ì¢…ëª©ëª…',
            'Market': 'ì‹œì¥êµ¬ë¶„',
            'Sector': 'ì„¹í„°',
            'Industry': 'ì‚°ì—…',
            'ListingDate': 'ìƒì¥ì¼',
            'SettleMonth': 'ê²°ì‚°ì›”',
            'Representative': 'ëŒ€í‘œìëª…',
            'HomePage': 'í™ˆí˜ì´ì§€',
            'Region': 'ì§€ì—­'
        })
        
        # ì¢…ëª©ì½”ë“œ 6ìë¦¬ë¡œ ë§ì¶”ê¸°
        kospi_list['ì¢…ëª©ì½”ë“œ'] = kospi_list['ì¢…ëª©ì½”ë“œ'].str.zfill(6)
        
        # data í´ë”ì— CSV íŒŒì¼ë¡œ ì €ì¥
        import os
        data_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), 'data')
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
            
        file_path = os.path.join(data_dir, 'kospi_list.csv')
        kospi_list.to_csv(file_path, index=False, encoding='utf-8')
        
        print(f"KOSPI ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_path}")
        return True
        
    except Exception as e:
        print(f"KOSPI ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

